{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7b69d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_path = r'C:\\gesture\\train'\n",
    "test_path = r'C:\\gesture\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf88442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3655cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3023a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ashik\\AppData\\Local\\Temp\\ipykernel_21652\\200021371.py\", line 1, in <cell line: 1>\n      history2 = model.fit(train_batches, epochs=10,  validation_data = test_batches)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[10,10] labels_size=[10,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_853]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_batches\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ashik\\AppData\\Local\\Temp\\ipykernel_21652\\200021371.py\", line 1, in <cell line: 1>\n      history2 = model.fit(train_batches, epochs=10,  validation_data = test_batches)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"C:\\Users\\ashik\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[10,10] labels_size=[10,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_853]"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=10,  validation_data = test_batches)\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#Once the model is fitted we save the model using model.save()  function.\n",
    "\n",
    "\n",
    "model.save('best_model_dataflair3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1197f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"best_model_dataflair3.h5\")\n",
    "\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "ROI_top = 100\n",
    "ROI_bottom = 300\n",
    "ROI_right = 150\n",
    "ROI_left = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a53302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "\n",
    "    \n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "     #Fetching contours in the frame (These contours can be of hand or any other object in foreground) â€¦\n",
    "\n",
    "    contours, _ =cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If length of contours list = 0, means we didn't get any contours...\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Returning the hand segment(max contour) and the thresholded image of hand...\n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flipping the frame to prevent inverted image of captured frame...\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "\n",
    "\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\",\n",
    "  (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment = hand\n",
    "\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,\n",
    "      ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.imshow(\"Thesholded Hand Image\", thresholded)\n",
    "            \n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded,(1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, word_dict[np.argmax(pred)],(170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,\n",
    "    ROI_bottom), (255,128,0), 3)\n",
    "\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"DataFlair hand sign recognition_ _ _\",\n",
    "    (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d127704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3da33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
